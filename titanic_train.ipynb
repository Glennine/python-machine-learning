{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "titanic = pd.read_csv(\"d:\\BaiduNetdiskDownload/titanic_train.csv\")\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.002015    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   29.699118    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].mean())\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(titanic['Sex'].unique())#几种可能性\n",
    "titanic.loc[titanic['Sex']=='male','Sex'] = 0\n",
    "titanic.loc[titanic['Sex']=='female','Sex'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "print(titanic['Embarked'].unique())\n",
    "plt.bar(np.arange(len(titanic['Embarked'].value_counts()))+0.5,titanic['Embarked'].value_counts())\n",
    "plt.xticks(np.arange(len(titanic['Embarked'].value_counts()))+0.5,titanic['Embarked'].value_counts().index)\n",
    "for x,y in zip(np.arange(len(titanic['Embarked'].value_counts()))+0.5,titanic['Embarked'].value_counts()):\n",
    "               plt.text(x,y,y,ha=\"center\", va=\"bottom\")\n",
    "plt.show()\n",
    "#把最多的填充给空白处\n",
    "titanic['Embarked'] = titanic['Embarked'].fillna('S')\n",
    "titanic.loc[titanic['Embarked']=='S','Embarked'] = 1\n",
    "titanic.loc[titanic['Embarked']=='C','Embarked'] = 2\n",
    "titanic.loc[titanic['Embarked']=='Q','Embarked'] = 3\n",
    "print(len(titanic['Embarked']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "0       3    0  22.0      1      0   7.2500         1\n",
      "1       1    1  38.0      1      0  71.2833         2\n",
      "2       3    1  26.0      0      0   7.9250         1\n",
      "3       1    1  35.0      1      0  53.1000         1\n",
      "4       3    0  35.0      0      0   8.0500         1\n"
     ]
    }
   ],
   "source": [
    "#进行学习\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "predictors = titanic.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis=1)\n",
    "x = predictors\n",
    "print(x.head())\n",
    "y = titanic['Survived']\n",
    "#print(predictors.head()),还剩6个特征量\n",
    "lr = LinearRegression()\n",
    "kf=KFold(n_splits=3,random_state=1)\n",
    "kf.get_n_splits(x)#交叉验证的倍数\n",
    "predictions = []\n",
    "#for train_index, test_index in kf.split(x):\n",
    " #   x_train, x_test = x[train_index], x[test_index]\n",
    "  #  y_train, y_test = y[train_index], y[test_index]\n",
    "   # lr.fit(x_train,y_train)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534 179 178\n"
     ]
    }
   ],
   "source": [
    "#进行学习\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "predictors = titanic.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis=1)\n",
    "x = predictors\n",
    "y = titanic['Survived']\n",
    "lr = LinearRegression()\n",
    "x_tt,x_validation,y_tt,y_validation = train_test_split(x,y,test_size = 0.2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_tt,y_tt,test_size = 0.25)\n",
    "print(len(x_train),len(x_validation),len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef:拟合参数 [-1.73404235e-01  4.99472800e-01 -5.86896720e-03 -4.16160575e-02\n",
      " -1.40861513e-02  3.46106921e-04  3.94070202e-02]\n",
      "MSE: 0.142453316769581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "features= x\n",
    "label = y\n",
    "regr=LinearRegression()\n",
    "regr=Ridge(alpha=1)\n",
    "regr=Lasso(alpha=0.001)\n",
    "regr.fit(features.values,label.values)\n",
    "y_pred=regr.predict(features.values)\n",
    "print(\"Coef:拟合参数\",regr.coef_)\n",
    "from sklearn.metrics import mean_squared_error#判断好坏\n",
    "print(\"MSE:\",mean_squared_error(y_pred,label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.7877094972067039\n",
      "REC: 0.6805555555555556\n",
      "F-Score: 0.7205882352941176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression(solver=\"sag\",max_iter=10000)\n",
    "#可见这个不是单纯的线性可以解决，需要高维解决\n",
    "lgr.fit(x_train,y_train)\n",
    "y_pred = lgr.predict(x_validation)\n",
    "print(\"ACC:\",accuracy_score(y_validation,y_pred))\n",
    "print(\"REC:\",recall_score(y_validation,y_pred))\n",
    "print(\"F-Score:\",f1_score(y_validation,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:\n",
      "ACC: 0.8156424581005587\n",
      "REC: 0.7638888888888888\n",
      "F-Score: 0.7692307692307692\n",
      "decide tree:\n",
      "ACC: 0.7821229050279329\n",
      "REC: 0.7083333333333334\n",
      "F-Score: 0.723404255319149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "rfc_clf = RandomForestClassifier(n_estimators=10,min_samples_split=4,\\\n",
    "                                 min_samples_leaf=2,max_features=None)\n",
    "rfc_clf.fit(x_train,y_train)\n",
    "y_pred = rfc_clf.predict(x_validation)\n",
    "print(\"random forest:\\nACC:\",accuracy_score(y_validation,y_pred))\n",
    "print(\"REC:\",recall_score(y_validation,y_pred))\n",
    "print(\"F-Score:\",f1_score(y_validation,y_pred))\n",
    "dtc_clf = DecisionTreeClassifier()\n",
    "dtc_clf.fit(x_train,y_train)\n",
    "y_pred = dtc_clf.predict(x_validation)\n",
    "print(\"decide tree:\\nACC:\",accuracy_score(y_validation,y_pred))\n",
    "print(\"REC:\",recall_score(y_validation,y_pred))\n",
    "print(\"F-Score:\",f1_score(y_validation,y_pred))#在不知道哪个更好的时候就先带入随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Mlle          2\n",
      "Col           2\n",
      "Jonkheer      1\n",
      "Countess      1\n",
      "Mme           1\n",
      "Sir           1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Capt          1\n",
      "Don           1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#由于准确率过低，考虑增加特征\n",
    "import re\n",
    "titanic['FamilySize']=titanic['SibSp']+titanic['Parch']\n",
    "titanic['NameLength']=titanic['Name'].apply(lambda x:len(x))\n",
    "\n",
    "def get_title(name):\n",
    "     # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif #choose best\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-121d73da9a31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mx_tt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2094\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2096\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7, 891]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\",]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "from sklearn.model_selection import train_test_split\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\",\"Fare\",  \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "x = predictors\n",
    "y = titanic['Survived']\n",
    "lr = LinearRegression()\n",
    "x_tt,x_validation,y_tt,y_validation = train_test_split(x,y,test_size = 0.2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_tt,y_tt,test_size = 0.25)\n",
    "print(len(x_train),len(x_validation),len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'n_splits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f3136c81b14b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Initialize the cross validation folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for argument 'n_splits'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\",]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_splits=3, random_state=1)\n",
    "kf.get_n_splits(titanic.shape[0])\n",
    "predictions = []\n",
    "for train, test in kf.split(titanic.shape[0]):\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
